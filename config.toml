# high-level behavior
seed = 42
fast_dev_run = false
regenerate = true
tune = false
train = false
evaluate = false
# model_id = "answerdotai/ModernBERT-base"
model_id = "bert-base-uncased"
verbose = true

[dataset]
input_path =  "data/raw/hyperpartisan.csv" # "data/raw/arxiv11/data" 
output_path = "data/processed/hyperpartisan.parquet" # "data/processed/arxiv11"
train_size = 0.8
max_length = 256
chunk_length = 256
overlap = 32

[dataloader]
batch_size = 16
pin_memory = true
num_workers = 0

[database]
path = "data/db/"
tbl_name = "hyperpartisan"
num_partitions = 256
num_sub_vectors = 96

[model]
num_queries = 8
k_neighbors = 4
d_model = 0 # inferred at run time
nheads = 1
dim_feedforward = 512
num_layers = 1
dropout = 0.1
output_dim = 0 # inferred at run time
# temperature = 0.05 # TODO currently not implemented
query_ini_random = false

[optimizer]
lr = 1e-4
weight_decay = 0.0001

[trainer]
max_epochs = 20
save_path = "models/hyperpartisan.pt"
gradient_clip = 1.0
ignore_index = -100
eval_every_n_epochs = 1

[tuner]
path = "results/hyperparameters.json"
checkpoint = "models/hyperpartisan.pt"
n_trials = 16
prune = false

[evaluator]
n_bootstraps = 1000
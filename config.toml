# high-level behavior
seed = 42
fast_dev_run = false
regenerate = true
tune = false
train = false
evaluate = false
model_id = "bert-base-uncased"
verbose = true

[dataset]
in_path =  "data/raw/" # "data/raw/arxiv11/data" 
inter_path = "data/intermediate/" # "data/intermediate/arxiv11"
out_path = "data/processed/" # "data/processed/arxiv11"
train_size = 0.8
max_length = 128
chunk_length = 128
overlap = 32

[dataloader]
batch_size = 16
pin_memory = true
num_workers = 0

[database]
path = "data/db/"
num_partitions = 256
num_sub_vectors = 96
k_neighbors = 4

[model]
num_queries = 32
d_model = 0 # inferred at run time
nhead = 1
dim_feedforward = 256
num_layers = 1
dropout = 0.1
output_dim = 0 # inferred at run time
query_ini_random = false

[optimizer]
lr = 1e-4
weight_decay = 0.0001

[trainer]
max_epochs = 3
save_path = "models/hyperpartisan.pt"
gradient_clip = 1.0
ignore_index = -100
eval_every_n_epochs = 1
temperature = 1.0

[tuner]
path = "models/hyperparameters.json"
checkpoint = "models/hyperpartisan.pt"
n_trials = 10
prune = false

[hparams]
[hparams.max_epochs]
name = "max_epochs"
low = 2
high = 8
[hparams.lr]
name = "lr"
low = 1e-5
high = 1e-3
[hparams.weight_decay]
name = "weight_decay"
low = 1e-5
high = 1e-2
[hparams.temperature]
name = "temperature"
low = 0.1
high = 2.0

[evaluator]
path = "data/results.parquet"
n_bootstraps = 100


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3428a7e-c197-49aa-8fea-5ba3489ff840",
   "metadata": {},
   "source": [
    "## set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908cb33-e950-4ccd-ad81-afb2839fa215",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --no-cache-dir llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
    "!python3 -m pip install googlesearch-python bs4 charset-normalizer requests-html lxml_html_clean\n",
    "\n",
    "from pathlib import Path\n",
    "if not Path('./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf').exists():\n",
    "    !wget https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908567c3-971f-45e6-898b-5b8895316879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Load the model onto GPU\n",
    "llama3 = Llama(\n",
    "    \"./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\",\n",
    "    verbose=False,\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=16384,    # n_ctx_train (131072) -- the full capacity\n",
    ")\n",
    "\n",
    "def generate_response(_model: Llama, _messages: str) -> str:\n",
    "    '''\n",
    "    This function will inference the model with given messages.\n",
    "    '''\n",
    "    _output = _model.create_chat_completion(\n",
    "        _messages,\n",
    "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
    "        max_tokens=512,    \n",
    "        temperature=0.5,     \n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return _output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d387c77-a7e1-44f9-8665-6601daf6e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case\n",
    "\n",
    "test_question=''\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are LLaMA-3.1-8B\"},  \n",
    "    {\"role\": \"user\", \"content\": test_question}, \n",
    "]\n",
    "\n",
    "print(generate_response(llama3, messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07a1b58-8536-4320-8e5e-c9786f4dd9b5",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c4c2862-ede0-4baa-abb3-801b71ae6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMAgent():\n",
    "    \n",
    "    def __init__(self, role_description: str, task_description: str, llm:str=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\"):\n",
    "        self.role_description = role_description  \n",
    "        self.task_description = task_description   \n",
    "        self.llm = llm  \n",
    "        \n",
    "    def inference(self, message:str) -> str:\n",
    "        if self.llm == 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF': \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": f\"{self.role_description}\"},  \n",
    "                {\"role\": \"user\", \"content\": f\"{self.task_description}\\n{message}\"}, \n",
    "            ]\n",
    "            return generate_response(llama3, messages)\n",
    "        else: # prepare for other models\n",
    "            ...\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a4c65e-32b6-4bc5-9b3c-dde659bb235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DOCTOR\n",
    "\n",
    "medical_explanation_agent = LLMAgent(\n",
    "    role_description=(\n",
    "        \"You are an AI model interpretation specialist with expertise in machine learning applications \"\n",
    "        \"in healthcare, particularly in autism spectrum disorder detection. Your role is to explain \"\n",
    "        \"AI model predictions to medical professionals, helping them understand how the model processes \"\n",
    "        \"clinical data to generate predictions. You have deep knowledge of both the technical aspects \"\n",
    "        \"of machine learning models and clinical practice, enabling you to bridge the gap between \"\n",
    "        \"AI technology and medical decision-making.\"\n",
    "    ),\n",
    "    \n",
    "    task_description=(\n",
    "        \"Based on the clinical record excerpt and the IRIS model's prediction below, provide a technical \"\n",
    "        \"explanation to medical professionals about how and why the model generated this prediction. \"\n",
    "        \"Your explanation should:\\n\"\n",
    "        \"1. Clarify the relationship between the observed clinical features and the model's prediction\\n\"\n",
    "        \"2. Distinguish between correlation and causation, emphasizing that detected patterns may indicate \"\n",
    "        \"association rather than direct causal relationships\\n\"\n",
    "        \"3. Explain the model's reasoning process and the significance of the retrieved clinical information\\n\"\n",
    "        \"4. Discuss potential limitations, uncertainties, or confounding factors\\n\"\n",
    "        \"5. Suggest clinical considerations for interpreting this prediction in the broader diagnostic context\\n\"\n",
    "        \"6. Be approximately 200-250 words to provide sufficient technical detail\\n\"\n",
    "        \"7. Use appropriate medical terminology while remaining clear and actionable\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1da9bc-8abb-45c0-94f9-03f1d49f7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TO PATIENT\n",
    "\n",
    "# explanation_agent = LLMAgent(\n",
    "#     role_description=(\n",
    "#         \"You are a compassionate medical explanation specialist with expertise in developmental disorders, \"\n",
    "#         \"particularly autism spectrum disorder. Your role is to explain medical findings to patients' families \"\n",
    "#         \"in a clear, supportive manner. You strike a balance between honesty and sensitivity, avoiding overly \"\n",
    "#         \"technical language while ensuring families understand the significance of the findings.\"\n",
    "#     ),\n",
    "#     task_description=(\n",
    "#         \"Based on the medical record excerpt and the model's prediction below, provide an explanation to the \"\n",
    "#         \"patient's family about why the model has determined this prediction regarding autism. Your explanation should:\\n\"\n",
    "#         \"1. Be clear and accessible to non-medical audiences\\n\"\n",
    "#         \"2. Be sensitive to the family's potential emotional response\\n\"\n",
    "#         \"3. Avoid overly technical terminology, or explain it when necessary\\n\"\n",
    "#         \"4. Be approximately 150-200 words in length\\n\"\n",
    "#         \"5. Acknowledge any uncertainties or limitations where appropriate\"\n",
    "#     ),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98db836-bcf6-4987-b418-5bb6068b12e7",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a501f75-0189-4313-9327-9439543cb437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chunks(file_path):\n",
    "    \"\"\"\n",
    "    Read chunks from file, separated by empty lines\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    chunks = [chunk.strip() for chunk in content.split('\\n\\n') if chunk.strip()]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def read_predictions(file_path):\n",
    "    \"\"\"\n",
    "    Read predictions from file, one prediction per line\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        predictions = [line.strip() for line in f if line.strip()]\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30be1fb6-fda6-44bb-9593-a1dab25db71b",
   "metadata": {},
   "source": [
    "### one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77bd4b-d92e-4daf-b51d-6b11f5c40011",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_explanations(chunks_file, predictions_file, factor):\n",
    "    \"\"\"\n",
    "    Generate explanations for each patient based on their chunk and prediction\n",
    "    \"\"\"\n",
    "    chunks = read_chunks(chunks_file)\n",
    "    predictions = read_predictions(predictions_file)\n",
    "    \n",
    "    # if len(chunks) != len(predictions):\n",
    "    #     raise ValueError(f\"Number of chunks ({len(chunks)}) does not match number of predictions ({len(predictions)})\")\n",
    "    \n",
    "    with open(\"explanation.txt\", \"w\") as explanation_file:\n",
    "        \n",
    "        # Process each patient\n",
    "        for i, (chunk, prediction) in enumerate(zip(chunks, predictions)):\n",
    "\n",
    "            is_autism = \"positive\" if prediction == \"1\" else \"negative\"\n",
    "            \n",
    "            input_text = (\n",
    "                f\"Factor: {factor}\\n\\n\"\n",
    "                f\"Medical Record Chunk:\\n{chunk}\\n\\n\"\n",
    "                f\"Model Prediction: {is_autism} for autism detected\"\n",
    "            )\n",
    "            explanation = explanation_agent.inference(input_text)\n",
    "            \n",
    "            # Print explanation\n",
    "            print(f\"\\nPatient {i+1} (Prediction: {is_autism} for autism)\")\n",
    "            print(explanation)\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            # Write to file\n",
    "            explanation_file.write(f\"Patient {i+1} (Prediction: {is_autism} for autism)\\n\\n\")\n",
    "            # explanation_file.write(\"-\" * 50 + \"\\n\")\n",
    "            explanation_file.write(explanation + \"\\n\\n\")\n",
    "            explanation_file.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    print(f\"\\nFinish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fce37-2fe9-4235-abc2-77780858a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "async def main():\n",
    "    factor = \"Late Talking\" \n",
    "    chunks_file = \"late_talking.txt\"\n",
    "    predictions_file = \"prediction.txt\"\n",
    "    \n",
    "    await generate_explanations(chunks_file, predictions_file, factor)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62280ac6-e62e-4701-9d59-1c9e4ee55751",
   "metadata": {},
   "source": [
    "### whole folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afae2ee-ec11-4433-af8f-1be2e80370ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_explanations(chunks_file, predictions_file, factor, output_file):\n",
    "    \"\"\"\n",
    "    Generate explanations for each patient based on their chunk and prediction\n",
    "    \"\"\"\n",
    "    chunks = read_chunks(chunks_file)\n",
    "    predictions = read_predictions(predictions_file)\n",
    "    \n",
    "    # Ensure number of chunks matches number of predictions\n",
    "    if len(chunks) != len(predictions):\n",
    "        raise ValueError(f\"Number of chunks ({len(chunks)}) does not match number of predictions ({len(predictions)}) for {factor}\")\n",
    "    \n",
    "    # Create factor header\n",
    "    factor_header = f\"\\nFactor: {factor}\\n{'=' * 50}\\n\\n\"\n",
    "    \n",
    "    # Write factor header to console and file\n",
    "    print(factor_header)\n",
    "    with open(output_file, \"a\") as explanation_file:\n",
    "        explanation_file.write(factor_header)\n",
    "    \n",
    "    # Process each patient\n",
    "    for i, (chunk, prediction) in enumerate(zip(chunks, predictions)):\n",
    "\n",
    "        is_autism = \"Signs of autism detected\" if prediction == \"1\" else \"No signs of autism detected\"\n",
    "        input_text = (\n",
    "            f\"Factor: {factor}\\n\\n\"\n",
    "            f\"Medical Record Excerpt:\\n{chunk}\\n\\n\"\n",
    "            f\"Model Prediction: {is_autism}\"\n",
    "        )\n",
    "        explanation = explanation_agent.inference(input_text)\n",
    "        \n",
    "        patient_output = (\n",
    "            f\"Patient {i+1} (Prediction: {is_autism})\\n\"\n",
    "            f\"{'-' * 50}\\n\"\n",
    "            f\"{explanation}\\n\"\n",
    "            f\"{'-' * 50}\\n\\n\"\n",
    "        )\n",
    "\n",
    "        print(patient_output)\n",
    "        with open(output_file, \"a\") as explanation_file:\n",
    "            explanation_file.write(patient_output)\n",
    "    \n",
    "    # Add closing separator\n",
    "    closing = f\"{'=' * 50}\\n\\n\"\n",
    "    with open(output_file, \"a\") as explanation_file:\n",
    "        explanation_file.write(closing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d9adfe0-53b4-45cd-8dcf-651c56aa2b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Factor: late_talking\n",
      "==================================================\n",
      "\n",
      "\n",
      "Patient 1 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that receiving a prediction like this can be a lot to take in, and it's completely normal to feel a range of emotions. Our model is suggesting that [NAME] may have some characteristics that are commonly seen in autism spectrum disorder, but it's essential to remember that this is just a prediction and not a definitive diagnosis.\n",
      "\n",
      "The model has identified that [NAME] has had some challenges with speech development, which is a common area of concern for children with autism. Specifically, the model has noted that [NAME] has been late to start talking and has not consistently used words to communicate. While it's great to hear that [NAME] has made progress in physical development, the fact that he has difficulty with speech and may seem like he's not listening at times raises some red flags.\n",
      "\n",
      "It's also important to note that the model has not taken into account [NAME]'s overall behavior and development in its prediction. We still have a lot to learn about [NAME] and will need to conduct further assessments to determine if this prediction holds true. I want to reassure you that we're here to support you and [NAME] every step of the way. We'll work together to understand what's going on and develop a plan to help him reach his full potential.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 2 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that it's natural to have questions and concerns about your child's development. The model's prediction is based on some specific behaviors and characteristics that we've observed in [NAME]. \n",
      "\n",
      "One of the key factors that contributed to this prediction is [NAME]'s delayed language development, often referred to as \"late-talking.\" This means that [NAME] didn't start speaking in words until he was around 10-11 months old, which is later than most children. While he has made some progress in the past few weeks, he still primarily communicates through babbling and gestures, rather than using words to express himself.\n",
      "\n",
      "We also noticed that [NAME] has some difficulty understanding and following complex instructions. He may need more time and support to understand what's being asked of him. These behaviors, along with some other observations, led the model to suggest that [NAME] may be at a higher risk for autism spectrum disorder (ASD). However, it's essential to remember that this is just a prediction, and we need to conduct more comprehensive evaluations to determine if [NAME] has ASD.\n",
      "\n",
      "We want to reassure you that we're here to support you and [NAME] throughout this process. We'll work together to gather more information and develop a plan that meets his unique needs.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 3 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by saying that we're here to support you and your child, and we'll do our best to understand what these findings mean for your family.\n",
      "\n",
      "The model has made a prediction based on some signs we've observed in your child. One of the main reasons for this prediction is that your child has been late to start talking. While he's now using a few words like \"mama\" and \"dog,\" he's not yet using many words to communicate. This is a bit concerning because babies typically start using words to communicate around 12-18 months.\n",
      "\n",
      "We're also taking into account that your child's older sister has autism, and you're seeing some similar signs in him. However, it's essential to remember that every child develops at their own pace, and it's not uncommon for children to exhibit different behaviors.\n",
      "\n",
      "We'll continue to monitor your child's development and work closely with you to better understand his needs. The model's prediction is just one tool we're using to guide our evaluation, and we'll need to gather more information before making any definitive conclusions.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 4 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that this conversation may be challenging, and I'm here to support you and your family. The model's prediction is based on certain behaviors and characteristics observed in your child. One of the key factors that contributed to this prediction is the child's history of late talking. Typically, children start babbling and making attempts to communicate around 9-12 months of age. In your child's case, they started babbling around 10 months, but since then, they've stopped speaking and haven't made attempts to communicate their needs. This is a concern because it may indicate a delay in language development.\n",
      "\n",
      "It's essential to note that late talking can be a feature of autism spectrum disorder (ASD), but it's not the only factor, and there are many other potential explanations for this behavior. The model's prediction is not a definitive diagnosis, but rather a suggestion that further evaluation and assessment may be necessary to determine the underlying cause of your child's behavior. We will work together to gather more information and explore all possible explanations for your child's development.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 5 (Prediction: No signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to take a moment to discuss the model's prediction with you. The model has determined that there are no signs of autism detected, but it's essential to understand that this prediction is based on a specific set of factors, including [NAME]'s developmental history.\n",
      "\n",
      "One factor that the model considered is [NAME]'s communication style. At 10-11 months, he started speaking in single words, which is a significant milestone. However, he has not yet started using language in a more directed way, such as pointing to objects or using gestures to communicate. This is often referred to as \"late talking.\" \n",
      "\n",
      "While late talking can be a concern, it doesn't necessarily mean that [NAME] has autism. Many children develop at their own pace, and some might need a bit more time to catch up. The model's prediction is based on the information available, but it's essential to remember that every child is unique, and only a comprehensive evaluation by a professional can provide a definitive diagnosis.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 6 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I'd like to take a moment to explain the model's prediction regarding autism. As you know, [child's name] has been experiencing some developmental delays and repetitive behaviors that have raised concerns for his mother. The model has analyzed these behaviors, including the fact that [child's name] is a late talker, meaning he hasn't started speaking as much as other children of his age.\n",
      "\n",
      "Late talking can be a red flag for autism, as some children with autism may have difficulty with language development. However, it's essential to note that late talking can have many causes, and not all late talkers will have autism. The model's prediction is based on a combination of factors, including [child's name]'s behaviors and developmental history.\n",
      "\n",
      "We want to emphasize that this prediction is not a definitive diagnosis, but rather a suggestion that we should further investigate [child's name]'s development. We will work closely with you to gather more information and conduct a comprehensive evaluation to determine the best course of action for [child's name]'s care.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 7 (Prediction: No signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to take a moment to discuss the model's prediction regarding autism. The model has taken into account various factors, including the medical record and some specific characteristics we've observed in [NAME]. One of these factors is the delayed talking, often referred to as \"late-talking.\" This means that [NAME] has taken a bit more time to start speaking compared to other children of the same age.\n",
      "\n",
      "While it's true that some children with autism may experience delayed language development, it's essential to remember that many children develop at their own pace. The model has looked at [NAME]'s overall development, including the fact that he's now saying \"mama\" and \"dada,\" and has considered the possibility that his language development might be a bit slower, but still within a typical range.\n",
      "\n",
      "It's also worth noting that [NAME] has a history of infantile spasms, which can sometimes impact language development. The model has taken this into account when making its prediction. While this doesn't rule out the possibility of autism entirely, it suggests that [NAME]'s development is more complex and influenced by other factors. I want to reassure you that we'll continue to closely monitor [NAME]'s development and adjust our approach as needed.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 8 (Prediction: No signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that this conversation may be challenging for you, and I'm here to support you throughout it. The model's prediction is based on a combination of factors, including the medical record and certain developmental milestones your child has achieved.\n",
      "\n",
      "The model has taken into account your child's ability to walk, run, climb stairs, and use both hands to grab his bottle. It has also considered his attempts to communicate by saying \"mama\" and \"dada.\" These skills are typically seen in children around this age, suggesting that he is developing at a typical pace.\n",
      "\n",
      "However, it's essential to remember that every child develops differently, and some may need more time or support. The model's prediction is not a definitive diagnosis, and it's possible that your child may still be at risk for autism or other developmental disorders. I want to assure you that we will continue to monitor your child's progress closely and provide any necessary support.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 9 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that this can be a difficult and uncertain time for families. The model's prediction of autism is not a definitive diagnosis, but rather a suggestion that there may be some underlying differences in communication and social interaction.\n",
      "\n",
      "The model has identified a pattern of late talking, which is when a child doesn't start using words to communicate by a certain age, typically around 16-18 months. In this case, the child was speaking fine at 15 months, but has since stopped using words altogether. This can be a concerning sign, as it may indicate that the child is having trouble with language development.\n",
      "\n",
      "It's essential to note that late talking can be a symptom of many different conditions, and autism is just one possible explanation. The model's prediction is based on patterns and trends in the child's behavior, but a definitive diagnosis can only be made through a comprehensive evaluation by a multidisciplinary team of professionals, including a pediatrician, psychologist, and speech therapist. We will need to gather more information and conduct further assessments to understand the child's needs and develop a plan to support her development.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Patient 10 (Prediction: Signs of autism detected)\n",
      "--------------------------------------------------\n",
      "I want to start by acknowledging that receiving a diagnosis or prediction can be a challenging and emotional experience for families. I'm here to support you and provide a clear understanding of the model's prediction regarding autism.\n",
      "\n",
      "The model has identified certain signs that may be related to autism, particularly in the area of communication and social interaction. One of the factors that caught the model's attention is that [NAME] started talking later than typical children. This is often referred to as a \"late-talking\" phenomenon. While it's not the only factor, it's one of the signs that, when combined with other observations, led the model to make this prediction.\n",
      "\n",
      "It's essential to note that every child develops at their own pace, and some may need a bit more time to start talking or walking. However, in [NAME]'s case, the model has identified some other signs that, when taken together, suggest a possible connection to autism. These signs include delayed gross motor skills, such as not crawling or walking yet, and some challenges with social interaction, like not always making eye contact.\n",
      "\n",
      "I want to emphasize that this prediction is not a definitive diagnosis, and more evaluation and testing are needed to confirm or rule out autism. We will work together to gather more information and provide a comprehensive assessment. If you have any questions or concerns, please don't hesitate to ask.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Processed factor: late_talking\n",
      "\n",
      "Factor: birth_weight\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processed factor: birth_weight\n",
      "\n",
      "Done! All explanations have been written to explanation.txt\n"
     ]
    }
   ],
   "source": [
    "# Main function to process all factors\n",
    "import os\n",
    "import asyncio\n",
    "import glob\n",
    "\n",
    "async def main():\n",
    "    \n",
    "    # Define paths\n",
    "    retrieved_chunk_dir = \"retrieved_chunk\"\n",
    "    pred_dir = \"pred\"\n",
    "    output_file = \"explanation.txt\"\n",
    "    \n",
    "    # Initialize or clear the output file\n",
    "    with open(output_file, \"w\") as f:\n",
    "        f.write(\"# Autism Factor Explanations\\n\\n\")\n",
    "    \n",
    "    # Get all chunk files\n",
    "    chunk_files = glob.glob(os.path.join(retrieved_chunk_dir, \"*.txt\"))\n",
    "    \n",
    "    # Process each factor\n",
    "    for chunks_file in chunk_files:\n",
    "        \n",
    "        # Extract factor name from filename\n",
    "        factor = os.path.basename(chunks_file).split('.')[0]\n",
    "        \n",
    "        # Construct path to corresponding prediction file\n",
    "        predictions_file = os.path.join(pred_dir, f\"{factor}_pred.txt\")\n",
    "        \n",
    "        # Check if prediction file exists\n",
    "        if not os.path.exists(predictions_file):\n",
    "            print(f\"Warning: Prediction file for {factor} not found at {predictions_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate explanations for this factor\n",
    "        try:\n",
    "            await generate_explanations(chunks_file, predictions_file, factor, output_file)\n",
    "            print(f\"Processed factor: {factor}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {factor}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nDone! All explanations have been written to {output_file}\")\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a669d6d-0547-487f-ad7b-4804dd6522ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
